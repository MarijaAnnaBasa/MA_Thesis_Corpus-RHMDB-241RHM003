# -*- coding: utf-8 -*-
"""Corpus._Volume.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NnZJxb6iq00TX1-DGAGA45HnIjnlhwls
"""

import os
import pandas as pd

import nltk
nltk.download('punkt')
nltk.download('punkt_tab')

from google.colab import drive
drive.mount('/content/drive')

path = '/content/drive/MyDrive/Scraped_Sputnik_FULL/Corpus_1'

csv_files = [os.path.join(path, f) for f in os.listdir(path) if f.endswith('.csv')]

#counting the number of files
num_files = len(csv_files)
print(f"\n Number of files: {num_files}\n")

all_articles = []

for file in csv_files:
    try:
        df = pd.read_csv(file, encoding='utf-8')
        if 'Text' in df.columns:
            all_articles.append(' '.join(df['Text'].dropna().astype(str)))
    except:
        print(f"Error reading: {file}")


#combining all text into one string
text = ' '.join(all_articles)

#removing BOM character
if text and text[0] == '\ufeff':
    text = text[1:]

tokens = nltk.word_tokenize(text)

total_words = len(tokens)
print(f"\nTotal number of tokens: {total_words:,}")

